# Interflow Backend

## üìã Description

Interflow Backend est une application Python con√ßue pour g√©rer la couverture des besoins en mati√®res premi√®res dans un contexte industriel. Le syst√®me analyse les besoins, v√©rifie leur couverture par les stocks existants, les r√©ceptions pr√©vues et les rapatriements, et fournit des analyses d√©taill√©es de couverture.

## üèóÔ∏è Architecture du Projet

### Structure des Dossiers

```
src/
‚îú‚îÄ‚îÄ api/                    # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Configuration principale de l'API
‚îÇ   ‚îú‚îÄ‚îÄ server.py          # Serveur API avec configuration
‚îÇ   ‚îú‚îÄ‚îÄ analyse.py         # Endpoints d'analyse de couverture
‚îÇ   ‚îú‚îÄ‚îÄ besoins.py         # Endpoints de gestion des besoins
‚îÇ   ‚îú‚îÄ‚îÄ stocks.py          # Endpoints de gestion des stocks
‚îÇ   ‚îú‚îÄ‚îÄ receptions.py      # Endpoints de gestion des r√©ceptions
‚îÇ   ‚îú‚îÄ‚îÄ rappatriements.py  # Endpoints de gestion des rapatriements
‚îÇ   ‚îî‚îÄ‚îÄ matieres.py        # Endpoints de gestion des mati√®res
‚îú‚îÄ‚îÄ services/               # Services m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ analyse_service.py         # Service d'analyse de couverture
‚îÇ   ‚îú‚îÄ‚îÄ analyse_display_service.py # Service d'affichage des r√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ data_service.py            # Service de gestion des donn√©es
‚îú‚îÄ‚îÄ models/                 # Mod√®les de donn√©es Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ besoin.py          # Mod√®le des besoins
‚îÇ   ‚îú‚îÄ‚îÄ stock.py           # Mod√®le des stocks
‚îÇ   ‚îú‚îÄ‚îÄ reception.py       # Mod√®le des r√©ceptions
‚îÇ   ‚îú‚îÄ‚îÄ rappatriement.py   # Mod√®le des rapatriements
‚îÇ   ‚îú‚îÄ‚îÄ matieres.py        # Mod√®le des mati√®res premi√®res
‚îÇ   ‚îî‚îÄ‚îÄ analyse.py         # Mod√®les d'analyse de couverture
‚îú‚îÄ‚îÄ repositories/           # Couche d'acc√®s aux donn√©es (Pattern Repository)
‚îÇ   ‚îú‚îÄ‚îÄ base_repository.py         # Repository de base g√©n√©rique
‚îÇ   ‚îú‚îÄ‚îÄ storage_strategies.py      # Strat√©gies de stockage (JSON, CSV)
‚îÇ   ‚îú‚îÄ‚îÄ besoins_repository.py      # Repository des besoins
‚îÇ   ‚îú‚îÄ‚îÄ stocks_repository.py       # Repository des stocks
‚îÇ   ‚îú‚îÄ‚îÄ receptions_repository.py   # Repository des r√©ceptions
‚îÇ   ‚îú‚îÄ‚îÄ rappatriements_repository.py # Repository des rapatriements
‚îÇ   ‚îî‚îÄ‚îÄ matieres_premieres_repository.py # Repository des mati√®res
‚îú‚îÄ‚îÄ scripts/               # Scripts utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ analyse.py         # Script principal d'analyse de couverture
‚îú‚îÄ‚îÄ lib/                   # Utilitaires et helpers
‚îÇ   ‚îú‚îÄ‚îÄ paths.py           # Gestion des chemins de fichiers
‚îÇ   ‚îî‚îÄ‚îÄ logging/           # Syst√®me de logging
‚îÇ       ‚îî‚îÄ‚îÄ analyse_logger.py # Logger pour les analyses
‚îî‚îÄ‚îÄ outputs/               # Sorties g√©n√©r√©es (logs, rapports)
    ‚îî‚îÄ‚îÄ logs/              # Fichiers de logs d'analyse
```

## üîÑ Architecture G√©n√©rale

```mermaid
graph TB
    subgraph "Couche Pr√©sentation"
        API[API FastAPI]
        CLI[Interface CLI analyse.py]
    end

    subgraph "Couche Services"
        AS[AnalyseService]
        ADS[AnalyseDisplayService]
        DS[DataService]
    end

    subgraph "Couche Repositories"
        BR[BesoinsRepository]
        SR[StocksRepository]
        RR[ReceptionsRepository]
        RAR[RappatriementsRepository]
        MR[MatieresPremieresRepository]
    end

    subgraph "Couche Donn√©es"
        JSON[Stockage JSON]
        CSV[Import CSV]
    end

    API --> AS
    CLI --> AS
    API --> ADS
    CLI --> ADS
    AS --> BR
    AS --> SR
    AS --> RR
    AS --> RAR
    BR --> JSON
    SR --> JSON
    RR --> JSON
    RAR --> JSON
    MR --> JSON
    DS --> CSV
```

## üìä Mod√®les de Donn√©es

### Mod√®les Principaux

```mermaid
classDiagram
    class Matiere {
        +code_mp: str
        +nom: str
        +description: str
        +fds: str
        +seveso: bool
    }

    class Besoin {
        +id: str
        +matiere: Matiere
        +quantite: float
        +echeance: datetime
        +etat: Etat
        +lot: str
    }

    class Stock {
        +article: str
        +libelle_article: str
        +quantite: float
        +magasin: str
        +emplacement: str
        +contenant: str
        +matiere: Matiere
        +statut_lot: str
    }

    class Reception {
        +id: str
        +type: TypeReception
        +matiere: Matiere
        +quantite: float
        +etat: EtatReception
        +date_creation: datetime
        +date_reception: datetime
        +fournisseur: str
    }

    class Rappatriement {
        +numero_transfert: str
        +responsable_diffusion: str
        +date_demande: datetime
        +adresse_destinataire: str
        +produits: List[ProduitRappatriement]
    }

    Besoin --> Matiere
    Stock --> Matiere
    Reception --> Matiere
    Rappatriement --> Matiere
```

### Mod√®les d'Analyse

```mermaid
classDiagram
    class AnalyseCouverture {
        +horizon_jours: int
        +date_initiale: datetime
        +date_limite: datetime
        +analyse_par_matiere: Dict[str, AnalyseMatiere]
        +statistiques_par_matiere: Dict[str, StatistiquesMatiere]
    }

    class AnalyseMatiere {
        +code_mp: str
        +nom_matiere: str
        +total_besoins: int
        +total_couverts: int
        +taux_couverture: float
        +quantite_besoin_totale: float
        +quantite_stock_internes: float
        +quantite_stock_externes: float
        +quantite_receptions: float
        +quantite_rappatriements: float
        +couverture_par_besoin: List[CouvertureBesoin]
        +analyse_chronologique: AnalyseChronologique
    }

    class CouvertureBesoin {
        +besoin: Besoin
        +quantite_besoin: float
        +quantite_disponible_couverture: float
        +etat_couverture: Etat
        +pourcentage_couverture: float
    }

    AnalyseCouverture --> AnalyseMatiere
    AnalyseMatiere --> CouvertureBesoin
    CouvertureBesoin --> Besoin
```

## üîß Services et Architecture

### Services Principaux

#### 1. AnalyseService
Service principal d'analyse de couverture des besoins :

```python
from services.analyse_service import AnalyseService

# Analyse compl√®te (toutes les mati√®res)
service = AnalyseService(besoins_repo, stocks_repo, receptions_repo, rappatriements_repo)
analyse_complete = service.analyze_coverage(date_initiale, horizon_days)

# Analyse d'une mati√®re sp√©cifique
analyse_matiere = service.analyze_matiere_coverage(code_mp, date_initiale, horizon_days)
```

**Fonctionnalit√©s :**
- Analyse de couverture par mati√®re
- Simulation chronologique de la consommation des stocks
- Prise en compte des r√©ceptions et rapatriements
- Calcul des statistiques de couverture
- Gestion des stocks internes vs externes

#### 2. AnalyseDisplayService
Service d'affichage format√© des r√©sultats :

```python
from services.analyse_display_service import AnalyseDisplayService

# Affichage de l'analyse compl√®te
AnalyseDisplayService.display_coverage_analysis(analyse)

# Transformation pour API
display_service = AnalyseDisplayService()
api_response = display_service.to_api_coverage_format(analyse)
```

**Fonctionnalit√©s :**
- Affichage format√© avec √©mojis et couleurs pour CLI
- Transformation en format JSON pour API
- R√©sum√© des statistiques globales
- D√©tail par mati√®re avec quantit√©s disponibles
- Export vers fichiers de logs

#### 3. DataService
Service de gestion des donn√©es :

```python
from services.data_service import DataService

data_service = DataService()
# Fonctionnalit√©s de rechargement et gestion des donn√©es
```

### Logique d'Analyse de Couverture

```mermaid
sequenceDiagram
    participant Script
    participant AnalyseService
    participant Repositories
    participant AnalyseDisplayService

    Script->>AnalyseService: analyze_coverage()
    AnalyseService->>Repositories: get_besoins_actuels_by_horizon()
    AnalyseService->>Repositories: get_internal_stocks_by_matiere()
    AnalyseService->>Repositories: get_external_stocks_by_matiere()
    AnalyseService->>Repositories: get_receptions_by_matiere()
    AnalyseService->>Repositories: get_rappatriements_by_matiere()

    AnalyseService->>AnalyseService: _analyze_matiere_coverage()
    Note over AnalyseService: Simulation chronologique<br/>des stocks disponibles

    AnalyseService-->>Script: AnalyseCouverture

    Script->>AnalyseDisplayService: display_coverage_analysis()
    AnalyseDisplayService-->>Script: Affichage format√©
```

## üöÄ Installation et Utilisation

### Pr√©requis

- Python 3.8+
- FastAPI (pour l'API)
- Pydantic (pour les mod√®les)
- Uvicorn (serveur ASGI)

### Installation

```bash
# Cloner le projet
git clone <repository-url>
cd interflow-backend

# Cr√©er un environnement virtuel
python -m venv .venv

# Activer l'environnement virtuel
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt
```

### Utilisation

#### üîç Script d'Analyse de Couverture (CLI)

Le script principal `analyse.py` permet d'analyser la couverture des besoins en mati√®res premi√®res :

```bash
# Analyse compl√®te (toutes les mati√®res)
python -m src.scripts.analyse -d=2025-09-26 --horizon=30

# Analyse d'une mati√®re sp√©cifique
python -m src.scripts.analyse -d=2025-09-26 --horizon=30 --code-mp=E05682

# Utilisation par d√©faut (aujourd'hui, horizon 5 jours)
python -m src.scripts.analyse
```

**Options disponibles :**
- `-d, --date` : Date initiale au format YYYY-MM-DD (d√©faut: aujourd'hui)
- `--horizon` : Horizon d'analyse en jours (d√©faut: 5)
- `--code-mp` : Code de mati√®re premi√®re pour filtrer l'analyse

#### üåê API REST

##### Lancement du serveur

```bash
# Via le serveur configur√© (recommand√©)
python src/api/server.py

# Via uvicorn directement
python -m uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# Via pyproject.toml (si install√© en package)
run_api

# Via Docker
docker-compose up
```

Le serveur sera accessible √† l'adresse : `http://localhost:5000` (serveur configur√©) ou `http://localhost:8000` (uvicorn direct)

##### Documentation API

- **Swagger UI** : `http://localhost:5000/docs`
- **ReDoc** : `http://localhost:5000/redoc`

##### Endpoints principaux

**Analyse de couverture :**
- `GET /analyse` - Analyse compl√®te de la couverture des besoins
- `GET /analyse/coverage/{code_mp}` - Analyse pour une mati√®re sp√©cifique
- `GET /analyse/matieres` - Liste des mati√®res disponibles

**Gestion des donn√©es :**
- `GET /besoins` - Liste des besoins
- `GET /stocks` - Liste des stocks
- `GET /receptions` - Liste des r√©ceptions
- `GET /rappatriements` - Liste des rapatriements
- `GET /matieres` - Liste des mati√®res premi√®res

#### Sorties et Logs

Le script g√©n√®re automatiquement :
- **Affichage console** : R√©sum√© format√© avec √©mojis et couleurs
- **Fichiers de logs** : Sauvegard√©s dans `outputs/logs/`
  - `analyse.log` : Analyse compl√®te
  - `analyse_{CODE_MP}.log` : Analyse d'une mati√®re sp√©cifique

**Exemple de sortie :**
```
üìä ANALYSE DE COUVERTURE DES BESOINS
================================================================================

üóìÔ∏è Horizon d'analyse: 30 jours
üìÖ Date initiale: 2025-09-26

üìà STATISTIQUES GLOBALES:
   ‚Ä¢ Total besoins analys√©s: 15
   ‚Ä¢ Total besoins couverts: 8
   ‚Ä¢ Taux de couverture: 53.3%

üß™ ANALYSE DE LA MATI√àRE:
   üì¶ Mati√®re: EUCALYPTOL NO (E05682)
      ‚Ä¢ Besoins: 5 | Couverts: 1
      ‚Ä¢ Taux couverture: 20.0%
      ‚Ä¢ Quantit√© besoin total: 820.0
      ‚Ä¢ Stock internes: 584.35
      ‚Ä¢ Stock externes: 8640.0
      ‚Ä¢ R√©ceptions pr√©vues: 250.0
      ‚Ä¢ Rapatriements: 0.0
      ‚Ä¢ Total disponible: 834.35
```

## üìà √âtats des Besoins

```mermaid
stateDiagram-v2
    [*] --> INCONNU: Cr√©ation du besoin
    INCONNU --> COUVERT: Couverture compl√®te trouv√©e
    INCONNU --> PARTIEL: Couverture partielle seulement
    PARTIEL --> COUVERT: Couverture compl√®te atteinte
    COUVERT --> [*]: Besoin satisfait
    INCONNU --> NON_COUVERT: Aucune couverture trouv√©e
    NON_COUVERT --> PARTIEL: Couverture partielle trouv√©e
    NON_COUVERT --> COUVERT: Couverture compl√®te trouv√©e
```

## üîÑ Flux de Donn√©es

```mermaid
graph LR
    subgraph "Sources de Donn√©es"
        CSV[Fichiers CSV]
        JSON[Stockage JSON]
    end

    subgraph "Repositories"
        REPOS[Repositories avec<br/>Strategy Pattern]
    end

    subgraph "Services"
        AS[AnalyseService]
        DS[DataService]
    end

    subgraph "Sorties"
        CLI[CLI Analysis]
        API[API Responses]
        LOGS[Log Files]
    end

    CSV --> DS
    DS --> JSON
    JSON --> REPOS
    REPOS --> AS
    AS --> CLI
    AS --> API
    AS --> LOGS
```

## üõ†Ô∏è Fonctionnalit√©s Principales

- **Analyse de couverture** : √âvaluation de la disponibilit√© des mati√®res premi√®res
- **Gestion multi-sources** : Stocks, r√©ceptions, rapatriements
- **API REST compl√®te** : Interface FastAPI pour int√©gration
- **Interface CLI** : Script d'analyse en ligne de commande
- **Mod√®les typ√©s** : Validation Pydantic
- **Pattern Repository** : Abstraction de la couche donn√©es
- **Strat√©gies de stockage** : Support JSON et CSV
- **Logging avanc√©** : Tra√ßabilit√© des analyses
- **Simulation chronologique** : Analyse temporelle des besoins

## üìù Notes Techniques

- **Architecture modulaire** : Services, repositories, mod√®les s√©par√©s
- **Pattern Strategy** : Strat√©gies de stockage interchangeables
- **Validation Pydantic** : Types et contraintes strictes
- **FastAPI** : API moderne avec documentation automatique
- **Logging contextualis√©** : Logs par analyse et mati√®re
- **Support Docker** : Conteneurisation compl√®te

## üîÆ √âvolutions Futures

- Int√©gration d'une base de donn√©es (PostgreSQL)
- Interface utilisateur web React/Vue
- Notifications en temps r√©el
- Optimisation des algorithmes de couverture
- R√®gles m√©tier configurables
- Workflows d'approbation
- Int√©gration avec syst√®mes ERP
